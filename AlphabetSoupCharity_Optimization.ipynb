{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Optimizing the Model"
      ],
      "metadata": {
        "id": "uoTeu7kp_phB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WNULZfn_-o_m"
      },
      "outputs": [],
      "source": [
        "# 1. Import Dependencies\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Load the CSV Data\n",
        "url = \"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\"\n",
        "application_df = pd.read_csv(url)"
      ],
      "metadata": {
        "id": "EavbH_qV_CmU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Preprocess the Data"
      ],
      "metadata": {
        "id": "trKW6XNE_GiP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop non-beneficial columns\n",
        "application_df.drop(['EIN', 'NAME'], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "TadJ9xr1_2qQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bin rare values for APPLICATION_TYPE\n",
        "application_type_counts = application_df['APPLICATION_TYPE'].value_counts()\n",
        "cutoff = 100  # Adjust this cutoff as needed\n",
        "application_types_to_replace = application_type_counts[application_type_counts < cutoff].index.tolist()\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app, \"Other\")"
      ],
      "metadata": {
        "id": "ED3112uQ_6UR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bin rare values for CLASSIFICATION\n",
        "classification_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "cutoff_class = 50  # Adjust this cutoff as needed\n",
        "classifications_to_replace = classification_counts[classification_counts < cutoff_class].index.tolist()\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls, \"Other\")\n"
      ],
      "metadata": {
        "id": "SAwAEQQ7_9Wx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert categorical columns to numeric using one-hot encoding\n",
        "categorical_columns = ['APPLICATION_TYPE', 'AFFILIATION', 'CLASSIFICATION',\n",
        "                       'USE_CASE', 'ORGANIZATION', 'STATUS',\n",
        "                       'INCOME_AMT', 'SPECIAL_CONSIDERATIONS']\n",
        "application_df = pd.get_dummies(application_df, columns=categorical_columns, drop_first=True)"
      ],
      "metadata": {
        "id": "i-mXqfevAAhw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into features and target\n",
        "X = application_df.drop('IS_SUCCESSFUL', axis=1)\n",
        "y = application_df['IS_SUCCESSFUL']"
      ],
      "metadata": {
        "id": "LsetqeqzADWe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into training and testing datasets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n"
      ],
      "metadata": {
        "id": "vv0WNU8cAFej"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "kF9-H9-rAHXe"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define an Optimized Neural Network Model\n",
        "\n",
        "optimized_nn = tf.keras.models.Sequential()"
      ],
      "metadata": {
        "id": "F1u912TEAL6O"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First hidden layer with 128 neurons and ReLU activation, plus input shape\n",
        "optimized_nn.add(tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c9lOHEsARo5",
        "outputId": "c539aa46-fefc-4dcc-b229-1ef4ca89a883"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropout layer for regularization\n",
        "optimized_nn.add(tf.keras.layers.Dropout(0.2))\n"
      ],
      "metadata": {
        "id": "cUGA41dmAV9z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Second hidden layer with 64 neurons and ReLU activation\n",
        "optimized_nn.add(tf.keras.layers.Dense(64, activation='relu'))"
      ],
      "metadata": {
        "id": "pB66fURcAXw5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Third hidden layer with 32 neurons and ReLU activation\n",
        "optimized_nn.add(tf.keras.layers.Dense(32, activation='relu'))"
      ],
      "metadata": {
        "id": "GdlVNihdAZ17"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Output layer for binary classification\n",
        "optimized_nn.add(tf.keras.layers.Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "nrEjnCexAbtP"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model using Adam optimizer and binary crossentropy loss\n",
        "optimized_nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "feecTX9jAd-K"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Set Up Callbacks"
      ],
      "metadata": {
        "id": "aXc3LYPUAgTV"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nTyZGf1hAhJC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EarlyStopping callback: stops training if validation loss doesn't improve for 10 epochs\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n"
      ],
      "metadata": {
        "id": "ZEUElKt6AiUA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom callback to save model weights every 5 epochs\n",
        "# This callback saves weights to a file ending with \".weights.h5\" every 5 epochs.\n",
        "class CustomModelCheckpoint(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, save_every):\n",
        "        super().__init__()\n",
        "        self.save_every = save_every\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % self.save_every == 0:\n",
        "            filepath = f'optimized_weights_epoch_{epoch + 1:02d}.weights.h5'\n",
        "            self.model.save_weights(filepath)\n",
        "            print(f'\\nSaved weights at epoch {epoch + 1} to {filepath}')\n",
        "\n",
        "custom_checkpoint = CustomModelCheckpoint(save_every=5)\n"
      ],
      "metadata": {
        "id": "bnPKJFCOAly0"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Train the Optimized Model\n",
        "history_optimized = optimized_nn.fit(\n",
        "    X_train_scaled,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop, custom_checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqaejJsYAoWw",
        "outputId": "1f8f09b6-1dbb-4437-c2f9-2a8dd112c968"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.6888 - loss: 0.6002 - val_accuracy: 0.7341 - val_loss: 0.5489\n",
            "Epoch 2/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7213 - loss: 0.5645 - val_accuracy: 0.7380 - val_loss: 0.5450\n",
            "Epoch 3/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7207 - loss: 0.5613 - val_accuracy: 0.7403 - val_loss: 0.5432\n",
            "Epoch 4/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7305 - loss: 0.5528 - val_accuracy: 0.7314 - val_loss: 0.5469\n",
            "Epoch 5/200\n",
            "\u001b[1m599/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7261 - loss: 0.5562\n",
            "Saved weights at epoch 5 to optimized_weights_epoch_05.weights.h5\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7262 - loss: 0.5562 - val_accuracy: 0.7399 - val_loss: 0.5434\n",
            "Epoch 6/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7297 - loss: 0.5498 - val_accuracy: 0.7395 - val_loss: 0.5443\n",
            "Epoch 7/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7359 - loss: 0.5459 - val_accuracy: 0.7384 - val_loss: 0.5411\n",
            "Epoch 8/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.5464 - val_accuracy: 0.7393 - val_loss: 0.5415\n",
            "Epoch 9/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7315 - loss: 0.5485 - val_accuracy: 0.7416 - val_loss: 0.5426\n",
            "Epoch 10/200\n",
            "\u001b[1m595/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 0.5464\n",
            "Saved weights at epoch 10 to optimized_weights_epoch_10.weights.h5\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7324 - loss: 0.5464 - val_accuracy: 0.7380 - val_loss: 0.5432\n",
            "Epoch 11/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 5ms/step - accuracy: 0.7333 - loss: 0.5447 - val_accuracy: 0.7355 - val_loss: 0.5418\n",
            "Epoch 12/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7376 - loss: 0.5410 - val_accuracy: 0.7380 - val_loss: 0.5451\n",
            "Epoch 13/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7417 - loss: 0.5366 - val_accuracy: 0.7376 - val_loss: 0.5443\n",
            "Epoch 14/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7342 - loss: 0.5459 - val_accuracy: 0.7395 - val_loss: 0.5464\n",
            "Epoch 15/200\n",
            "\u001b[1m600/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7304 - loss: 0.5450\n",
            "Saved weights at epoch 15 to optimized_weights_epoch_15.weights.h5\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7304 - loss: 0.5450 - val_accuracy: 0.7395 - val_loss: 0.5433\n",
            "Epoch 16/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7261 - loss: 0.5518 - val_accuracy: 0.7389 - val_loss: 0.5435\n",
            "Epoch 17/200\n",
            "\u001b[1m601/601\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7291 - loss: 0.5462 - val_accuracy: 0.7378 - val_loss: 0.5422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Evaluate the Optimized Model on Test Data\n",
        "opt_loss, opt_accuracy = optimized_nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Optimized Model - Loss: {opt_loss}, Accuracy: {opt_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOXJhIiaA5rn",
        "outputId": "b69b5e24-a110-4a41-bdfc-1144a3001e85"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "322/322 - 2s - 5ms/step - accuracy: 0.7327 - loss: 0.5528\n",
            "Optimized Model - Loss: 0.5528254508972168, Accuracy: 0.7326530814170837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Save the Optimized Model to an HDF5 File\n",
        "optimized_nn.save(\"AlphabetSoupCharity_Optimization.h5\")"
      ],
      "metadata": {
        "id": "tphxs8mUA_Mz",
        "outputId": "d2f8cf92-19b2-48a1-d757-7469e4ea549f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}